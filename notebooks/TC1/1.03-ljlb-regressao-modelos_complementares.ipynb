{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objetivo: Regressão no dataset “Real estate valuation” (UCI) com modelos do scikit-learn\n",
    "\n",
    "    Reaproveitar suas funções utilitárias (aux.*) para métricas (incluindo Hit@10), correlações e análise de resíduos.\n",
    "\n",
    "    Avaliar modelos adicionais além de Perceptron Logístico/MLP:\n",
    "    SVR (linear/rbf), DecisionTreeRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, BaggingRegressor.\n",
    "\n",
    "    Comparar 4 tratamentos de features: sem normalização, z-score, min-max e interquartil (IQR).\n",
    "\n",
    "    Selecionar o melhor absoluto priorizando Hit@10 (depois Hit@20, R² e, por fim, RMSE menor).\n",
    "\n",
    "    Manter k-fold e toda a impressão/análise via aux.imprimir_metricas, aux.imprimir_correlacoes e aux.analisar_residuos.\n"
   ],
   "id": "4eb19b6fb6454e54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:17:33.246540Z",
     "start_time": "2025-08-10T22:17:33.068430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Modelos sklearn\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor, BaggingRegressor\n",
    ")\n",
    "\n",
    "# Pacote do trabalho (funções utilitárias)\n",
    "from trabalho_ic_aplicada.models import aux\n",
    "\n",
    "np.random.seed(42)\n"
   ],
   "id": "7e0283cfc5fd6c9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-08-10 19:17:33.234\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mtrabalho_ic_aplicada.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/apo-note/Documents/Github/Trabalhos_IC_Aplicada\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [01] Carregamento do dataset e definição dos folds\n",
    "\n",
    "    Mesmo dataset e estrutura de folds do seu código, para comparabilidade.\n",
    "\n",
    "    Não normalizamos o alvo y (a normalização aqui será apenas nas features)."
   ],
   "id": "62f9b35442de3d8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:17:34.561237Z",
     "start_time": "2025-08-10T22:17:33.472550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "real_estate_valuation = fetch_ucirepo(id=477)\n",
    "\n",
    "# Nomes das variáveis (apenas informativo; a 1ª é data)\n",
    "features = real_estate_valuation.variables.iloc[1:, 0].values\n",
    "\n",
    "# Matriz X e vetor y\n",
    "X = real_estate_valuation.data.features.to_numpy()\n",
    "y = real_estate_valuation.data.targets.to_numpy().ravel()\n",
    "\n",
    "# Remove a 1ª coluna (data de transação)\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Índices dos folds (mesmo esquema do seu projeto)\n",
    "k_fold = aux.validacao_cruzada_kfold(X, y, k=10)\n",
    "len(k_fold)\n"
   ],
   "id": "c9eaac5b77e3cee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [02] Escalonadores de features e critério de seleção\n",
    "\n",
    "    Escalonadores:\n",
    "\n",
    "        \"none\" → sem normalização (pass-through)\n",
    "\n",
    "        \"zscore\" → StandardScaler\n",
    "\n",
    "        \"minmax\" → MinMaxScaler\n",
    "\n",
    "        \"iqr\" → RobustScaler (faixa interquartil)\n",
    "\n",
    "    Critério do “melhor absoluto”: ordenar por Hit@10 (desc), depois Hit@20 (desc), R² (desc) e RMSE (asc)."
   ],
   "id": "dc8f62084524423b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:17:34.611465Z",
     "start_time": "2025-08-10T22:17:34.606504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def make_scaler(kind: str):\n",
    "    if kind == \"none\":\n",
    "        return \"passthrough\"\n",
    "    if kind == \"zscore\":\n",
    "        return StandardScaler()\n",
    "    if kind == \"minmax\":\n",
    "        return MinMaxScaler()\n",
    "    if kind == \"iqr\":\n",
    "        # IQR ~ robust scaler\n",
    "        return RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
    "    raise ValueError(f\"Escalonador desconhecido: {kind}\")\n",
    "\n",
    "\n",
    "def rank_dataframe(df):\n",
    "    # Ordena por: Hit@10 desc, Hit@20 desc, R2 desc, RMSE asc\n",
    "    return df.sort_values(\n",
    "        by=[\"Hit@10_mean\", \"Hit@20_mean\", \"R2_mean\", \"RMSE_mean\"],\n",
    "        ascending=[False, False, False, True]\n",
    "    ).reset_index(drop=True)\n"
   ],
   "id": "36188436137553b9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [03] Avaliação k-fold por modelo × escalonador\n",
    "\n",
    "    Para cada combinação, treinamos e medimos EQM, RMSE, R², Hit@20 e Hit@10 com seu aux.calcular_metricas.\n",
    "\n",
    "    Também guardamos correlações e y_true/y_pred (treino/teste) para a análise de resíduos.\n",
    "\n",
    "    Observação: modelos do sklearn não expõem histórico de loss por época; por isso, não há loss_history aqui."
   ],
   "id": "7e5a9fa12f672d3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:17:34.691771Z",
     "start_time": "2025-08-10T22:17:34.678475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def evaluate_model_cv(model_name, model, scaler_kind, X, y, k_fold):\n",
    "    eqms, reqms, r2s, hit20s, hit10s = [], [], [], [], []\n",
    "    corrs_train, corrs_test = [], []\n",
    "    y_tr_all, y_tr_pred_all = [], []\n",
    "    y_te_all, y_te_pred_all = [], []\n",
    "\n",
    "    pipe = Pipeline([(\"scaler\", make_scaler(scaler_kind)), (\"model\", model)])\n",
    "\n",
    "    for tr_idx, te_idx in k_fold:\n",
    "        X_tr, X_te = X[tr_idx, :], X[te_idx, :]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "\n",
    "        # Treino & predição\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        y_tr_pred = pipe.predict(X_tr)\n",
    "        y_te_pred = pipe.predict(X_te)\n",
    "\n",
    "        # Correlações\n",
    "        corrs_train.append(np.corrcoef(y_tr, y_tr_pred)[0, 1])\n",
    "        corrs_test.append(np.corrcoef(y_te, y_te_pred)[0, 1])\n",
    "\n",
    "        # Métricas (teste) – usa sua função\n",
    "        eqm, reqm, r2, hit20, hit10, _ = aux.calcular_metricas(y_te, y_te_pred, aux)\n",
    "        eqms.append(eqm);\n",
    "        reqms.append(reqm);\n",
    "        r2s.append(r2)\n",
    "        hit20s.append(hit20);\n",
    "        hit10s.append(hit10)\n",
    "\n",
    "        # Acumula para análises globais\n",
    "        y_tr_all.extend(y_tr);\n",
    "        y_tr_pred_all.extend(y_tr_pred)\n",
    "        y_te_all.extend(y_te);\n",
    "        y_te_pred_all.extend(y_te_pred)\n",
    "\n",
    "    summary = {\n",
    "        \"model\": model_name,\n",
    "        \"scaler\": scaler_kind,\n",
    "        \"R2_mean\": float(np.mean(r2s)),\n",
    "        \"RMSE_mean\": float(np.mean(reqms)),\n",
    "        \"Hit@20_mean\": float(np.mean(hit20s)),\n",
    "        \"Hit@10_mean\": float(np.mean(hit10s)),\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"fold_metrics\": (eqms, reqms, r2s, hit20s, hit10s),\n",
    "        \"corrs\": (corrs_train, corrs_test),\n",
    "        \"y_all\": (\n",
    "            np.array(y_tr_all), np.array(y_tr_pred_all),\n",
    "            np.array(y_te_all), np.array(y_te_pred_all)\n",
    "        ),\n",
    "        # Mantemos o pipeline treinado do último fold apenas para referência\n",
    "        \"last_pipeline\": pipe\n",
    "    }\n"
   ],
   "id": "f94ba28d61cd7ef9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [04] Conjunto de modelos avaliados (sklearn)\n",
    "\n",
    "    SVR (linear e RBF)\n",
    "\n",
    "    Decision Tree\n",
    "\n",
    "    Random Forest\n",
    "\n",
    "    Extra Trees\n",
    "\n",
    "    Gradient Boosting\n",
    "\n",
    "    Bagging (base: árvore)\n",
    "\n",
    "    Nota sobre LSSVR: não há implementação nativa no scikit-learn. Se quiser, podemos incluir uma versão customizada depois."
   ],
   "id": "59b94dd33ec9854b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:17:34.783258Z",
     "start_time": "2025-08-10T22:17:34.778186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"SVR(linear)\": SVR(kernel=\"linear\", C=1.0, epsilon=0.1),\n",
    "    \"SVR(rbf)\": SVR(kernel=\"rbf\", C=10.0, gamma=\"scale\", epsilon=0.1),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "scalers = [\"none\", \"zscore\", \"minmax\", \"iqr\"]\n"
   ],
   "id": "4fb009cc5c92d07",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [05] Execução: resultados por modelo e ranking global\n",
    "\n",
    "    Para cada modelo, comparamos os 4 escalonadores e imprimimos as métricas do melhor caso (usando seu aux.imprimir_metricas e aux.imprimir_correlacoes).\n",
    "\n",
    "    Em seguida, criamos um ranking global (todas as combinações) priorizando Hit@10."
   ],
   "id": "8c501973271d971d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-08-10T22:17:34.869756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "best_per_model = {}\n",
    "rows_for_df = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model_results = []\n",
    "    for sc in scalers:\n",
    "        res = evaluate_model_cv(name, clone(model), sc, X, y, k_fold)\n",
    "        model_results.append(res)\n",
    "        all_results.append(res)\n",
    "        rows_for_df.append(res[\"summary\"])\n",
    "\n",
    "    # Ranking interno do modelo\n",
    "    df_model = rank_dataframe(pd.DataFrame([r[\"summary\"] for r in model_results]))\n",
    "    best_row = df_model.iloc[0].to_dict()\n",
    "    best_obj = next(r for r in model_results\n",
    "                    if r[\"summary\"][\"model\"] == best_row[\"model\"]\n",
    "                    and r[\"summary\"][\"scaler\"] == best_row[\"scaler\"])\n",
    "\n",
    "    best_per_model[name] = {\n",
    "        \"best_summary\": best_row,\n",
    "        \"ranking\": df_model,\n",
    "        \"result_obj\": best_obj\n",
    "    }\n",
    "\n",
    "    # ---- Impressões do melhor caso por modelo\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"Melhor para {name} | Escalonador: {best_row['scaler']}\")\n",
    "    print(f\"Hit@10={best_row['Hit@10_mean']:.4f} | Hit@20={best_row['Hit@20_mean']:.4f} | \"\n",
    "          f\"R²={best_row['R2_mean']:.4f} | RMSE={best_row['RMSE_mean']:.4f}\")\n",
    "\n",
    "    # Listas por fold para suas funções\n",
    "    eqms, reqms, r2s, hit20s, hit10s = best_obj[\"fold_metrics\"]\n",
    "    corr_tr, corr_te = best_obj[\"corrs\"]\n",
    "\n",
    "    aux.imprimir_metricas(eqms, reqms, r2s, hit20s, hit10s)\n",
    "    aux.imprimir_correlacoes(corr_tr, corr_te, r2s)\n",
    "\n",
    "# ---- Ranking global (todas as combinações)\n",
    "df_all = pd.DataFrame(rows_for_df)\n",
    "df_global = rank_dataframe(df_all)\n",
    "print(\"\\n\" + \"#\" * 90)\n",
    "print(\"TOP 10 combinações (global) — critério: Hit@10, Hit@20, R², RMSE\")\n",
    "print(df_global.head(10).to_string(index=False))\n"
   ],
   "id": "f654f0ce6b2b908e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [06] Análise de resíduos do melhor absoluto\n",
    "\n",
    "    Escolhemos a melhor combinação do ranking global e rodamos sua análise de resíduos com seus utilitários.\n",
    "\n",
    "    Observação: para estes modelos sklearn não há loss por época, então não chamamos aux.plot_folds_loss aqui."
   ],
   "id": "b8a43697d83f02e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_global = df_global.iloc[0].to_dict()\n",
    "best_global_obj = next(r for r in all_results\n",
    "                       if r[\"summary\"][\"model\"] == best_global[\"model\"]\n",
    "                       and r[\"summary\"][\"scaler\"] == best_global[\"scaler\"])\n",
    "\n",
    "y_tr, y_tr_pred, y_te, y_te_pred = best_global_obj[\"y_all\"]\n",
    "\n",
    "titulo = f\"Melhor global: {best_global['model']} | scaler={best_global['scaler']}\"\n",
    "aux.analisar_residuos(y_tr, y_tr_pred, y_te, y_te_pred, aux, titulo=titulo)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"MELHOR GLOBAL (prioridade: Hit@10)\")\n",
    "print(f\"Modelo: {best_global['model']} | Escalonador: {best_global['scaler']}\")\n",
    "print(f\"Hit@10={best_global['Hit@10_mean']:.4f} | Hit@20={best_global['Hit@20_mean']:.4f} | \"\n",
    "      f\"R²={best_global['R2_mean']:.4f} | RMSE={best_global['RMSE_mean']:.4f}\")\n"
   ],
   "id": "e6594f0d277ae792"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
