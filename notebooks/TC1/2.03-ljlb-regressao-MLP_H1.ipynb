{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objetivo: Regressão no dataset \"Real estate valuation\" (UCI), usando MLP.\n",
    "    - Avaliação por validação cruzada k-fold e análise de resíduos.\n"
   ],
   "id": "37e3d695bc0ae64b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:44:10.199141Z",
     "start_time": "2025-08-10T21:44:10.120879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "from trabalho_ic_aplicada.models import aux\n",
    "from trabalho_ic_aplicada.models import reg_mlp\n",
    "from trabalho_ic_aplicada.models.reg_perceptron import treinar_perceptron_reg, prever_perceptron_reg"
   ],
   "id": "6f0554331fcdbcad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-08-10 18:44:10.188\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mtrabalho_ic_aplicada.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: /home/apo-note/Documents/Github/Trabalhos_IC_Aplicada\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:44:11.481687Z",
     "start_time": "2025-08-10T21:44:10.319817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fetch dataset\n",
    "real_estate_valuation = fetch_ucirepo(id=477)\n",
    "\n",
    "features = real_estate_valuation.variables.iloc[1:, 0].values\n",
    "# data (as pandas dataframes)\n",
    "X = real_estate_valuation.data.features.to_numpy()\n",
    "\n",
    "# Removendo a primeira coluna (X1 transaction date) que não é um atributo relevante, segundo analise.\n",
    "X = X[:, 1:]\n",
    "\n",
    "y = real_estate_valuation.data.targets.to_numpy().ravel()\n",
    "\n",
    "\n",
    "k_fold = aux.validacao_cruzada_kfold(X,y,k=10)\n"
   ],
   "id": "449857452e3b257",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Search e Avaliação Melhor Caso MLP.",
   "id": "a5d4016fe9387011"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:44:11.529993Z",
     "start_time": "2025-08-10T21:44:11.520684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from trabalho_ic_aplicada.models import reg_mlp\n",
    "# import aux  # supondo que aux.calcular_metricas, etc. estejam em aux.py\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "def cross_val_mlp(X, y, k_fold, layer_sizes, activation, epochs, lr):\n",
    "    \"\"\"\n",
    "    Executa CV para um MLP de 1 camada oculta, retorna média de R2 e todas as curvas de loss.\n",
    "    \"\"\"\n",
    "    fold_r2 = []\n",
    "    fold_losses = []\n",
    "    for train_idx, test_idx in k_fold:\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx].reshape(-1,1), y[test_idx].reshape(-1,1)\n",
    "        # Normaliza X\n",
    "        scaler = QuantileTransformer(n_quantiles=min(X_tr.shape[0],1000), output_distribution='uniform')\n",
    "        X_tr_n = scaler.fit_transform(X_tr)\n",
    "        X_te_n = scaler.transform(X_te)\n",
    "        # Treina\n",
    "        W, loss_hist = reg_mlp.train_mlp_regression(\n",
    "            X_tr_n, y_tr,\n",
    "            layer_sizes=layer_sizes,\n",
    "            epochs=epochs,\n",
    "            eta_i=lr, eta_f=lr,\n",
    "            hidden_activation=activation,\n",
    "            output_activation='linear',\n",
    "            verbose=False\n",
    "        )\n",
    "        fold_losses.append(loss_hist)\n",
    "        # Previsão\n",
    "        y_pred = reg_mlp.predict_mlp_regression(X_te_n, W, activation, 'linear').reshape(-1,1)\n",
    "        # R2\n",
    "        _, _, r2, *_ = aux.calcular_metricas(y_te, y_pred, aux)\n",
    "        fold_r2.append(r2)\n",
    "    return np.mean(fold_r2), fold_losses\n",
    "\n",
    "def grid_search(X, y, k_fold, hidden_units, activations, epochs_list, lrs):\n",
    "    best = {'score': -np.inf}\n",
    "    for act in activations:\n",
    "        for hu in hidden_units:\n",
    "            for ep in epochs_list:\n",
    "                for lr in lrs:\n",
    "                    ls = [X.shape[1], hu, 1]\n",
    "                    mean_r2, _ = cross_val_mlp(X, y, k_fold, ls, act, ep, lr)\n",
    "                    print(f\"Act={act:<7} HU={hu:2d} Ep={ep:3d} LR={lr:.3g} → R²={mean_r2:.4f}\")\n",
    "                    if mean_r2 > best['score']:\n",
    "                        best.update({\n",
    "                            'layer_sizes': ls,\n",
    "                            'activation': act,\n",
    "                            'epochs': ep,\n",
    "                            'lr': lr,\n",
    "                            'score': mean_r2\n",
    "                        })\n",
    "    print(\"\\n=== Best config ===\")\n",
    "    print(best)\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "def random_search(X, y, k_fold, hidden_units, activations, epochs_list, lrs, n_iter=20, seed=42):\n",
    "    \"\"\"\n",
    "    Executa busca aleatória por hiperparâmetros para o MLP.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Gera todas as combinações possíveis\n",
    "    all_combinations = list(itertools.product(activations, hidden_units, epochs_list, lrs))\n",
    "    # Embaralha e pega n combinações aleatórias\n",
    "    sampled_combinations = random.sample(all_combinations, min(n_iter, len(all_combinations)))\n",
    "\n",
    "    best = {'score': -np.inf}\n",
    "    for act, hu, ep, lr in sampled_combinations:\n",
    "        ls = [X.shape[1], hu, 1]\n",
    "        mean_r2, _ = cross_val_mlp(X, y, k_fold, ls, act, ep, lr)\n",
    "        print(f\"Act={act:<7} HU={hu:2d} Ep={ep:3d} LR={lr:.3g} → R²={mean_r2:.4f}\")\n",
    "        if mean_r2 > best['score']:\n",
    "            best.update({\n",
    "                'layer_sizes': ls,\n",
    "                'activation': act,\n",
    "                'epochs': ep,\n",
    "                'lr': lr,\n",
    "                'score': mean_r2\n",
    "            })\n",
    "\n",
    "    print(\"\\n=== Best config ===\")\n",
    "    print(best)\n",
    "    return best"
   ],
   "id": "b5dc177c665b8955",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T22:21:23.503332Z",
     "start_time": "2025-08-10T21:44:11.583515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 1) Grid search\n",
    "hidden_units  = [4, 8, 16, 32, 64]\n",
    "activations   = ['sigmoid', 'tanh', 'relu', 'leaky_relu']\n",
    "epochs_list   = [100, 200, 300]\n",
    "learning_rates= [1e-3, 5e-3, 1e-2]\n",
    "\n",
    "# 1) Random search\n",
    "best_cfg = random_search(X, y, k_fold,\n",
    "                         hidden_units, activations,\n",
    "                         epochs_list, learning_rates,\n",
    "                         n_iter=60)  # você pode ajustar n_iter\n",
    "\n",
    "# best_cfg = grid_search(X, y, k_fold,\n",
    "#                        hidden_units, activations,\n",
    "#                        epochs_list, learning_rates)"
   ],
   "id": "df153261cce9087e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act=leaky_relu HU=32 Ep=100 LR=0.005 → R²=0.5916\n",
      "Act=sigmoid HU=32 Ep=100 LR=0.005 → R²=0.6645\n",
      "Act=sigmoid HU= 4 Ep=300 LR=0.001 → R²=0.6709\n",
      "Act=tanh    HU=16 Ep=300 LR=0.005 → R²=0.6612\n",
      "Act=tanh    HU= 8 Ep=300 LR=0.01 → R²=0.6453\n",
      "Act=tanh    HU= 8 Ep=200 LR=0.001 → R²=0.6624\n",
      "Act=sigmoid HU=32 Ep=300 LR=0.01 → R²=0.6705\n",
      "Act=sigmoid HU=16 Ep=300 LR=0.01 → R²=0.6552\n",
      "Act=leaky_relu HU= 4 Ep=200 LR=0.005 → R²=0.6073\n",
      "Act=sigmoid HU=16 Ep=200 LR=0.005 → R²=0.6732\n",
      "Act=leaky_relu HU= 8 Ep=300 LR=0.005 → R²=0.6553\n",
      "Act=relu    HU=16 Ep=100 LR=0.001 → R²=0.6660\n",
      "Act=sigmoid HU= 4 Ep=300 LR=0.01 → R²=0.6265\n",
      "Act=sigmoid HU= 4 Ep=300 LR=0.005 → R²=0.6347\n",
      "Act=sigmoid HU=16 Ep=200 LR=0.01 → R²=0.6626\n",
      "Act=tanh    HU= 8 Ep=100 LR=0.005 → R²=0.6223\n",
      "Act=tanh    HU= 8 Ep=200 LR=0.01 → R²=0.6190\n",
      "Act=relu    HU=64 Ep=200 LR=0.001 → R²=0.6665\n",
      "Act=leaky_relu HU=16 Ep=100 LR=0.005 → R²=0.6641\n",
      "Act=leaky_relu HU=64 Ep=300 LR=0.001 → R²=0.6438\n",
      "Act=leaky_relu HU= 4 Ep=300 LR=0.01 → R²=0.6483\n",
      "Act=tanh    HU= 4 Ep=200 LR=0.01 → R²=0.5678\n",
      "Act=leaky_relu HU=64 Ep=100 LR=0.001 → R²=0.6416\n",
      "Act=relu    HU= 8 Ep=300 LR=0.01 → R²=0.3583\n",
      "Act=tanh    HU= 8 Ep=100 LR=0.01 → R²=0.6327\n",
      "Act=relu    HU=16 Ep=300 LR=0.001 → R²=0.6131\n",
      "Act=leaky_relu HU= 8 Ep=300 LR=0.001 → R²=0.6231\n",
      "Act=tanh    HU=16 Ep=300 LR=0.01 → R²=0.6457\n",
      "Act=sigmoid HU= 4 Ep=100 LR=0.005 → R²=0.6537\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m learning_rates\u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1e-3\u001B[39m, \u001B[38;5;241m5e-3\u001B[39m, \u001B[38;5;241m1e-2\u001B[39m]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# 1) Random search\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m best_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mhidden_units\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mepochs_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# você pode ajustar n_iter\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# best_cfg = grid_search(X, y, k_fold,\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#                        hidden_units, activations,\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#                        epochs_list, learning_rates)\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[3], line 78\u001B[0m, in \u001B[0;36mrandom_search\u001B[0;34m(X, y, k_fold, hidden_units, activations, epochs_list, lrs, n_iter, seed)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m act, hu, ep, lr \u001B[38;5;129;01min\u001B[39;00m sampled_combinations:\n\u001B[1;32m     77\u001B[0m     ls \u001B[38;5;241m=\u001B[39m [X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], hu, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 78\u001B[0m     mean_r2, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_mlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAct=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mact\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<7\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m HU=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhu\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m2d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Ep=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mep\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m3d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m LR=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3g\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m → R²=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmean_r2\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mean_r2 \u001B[38;5;241m>\u001B[39m best[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "Cell \u001B[0;32mIn[3], line 23\u001B[0m, in \u001B[0;36mcross_val_mlp\u001B[0;34m(X, y, k_fold, layer_sizes, activation, epochs, lr)\u001B[0m\n\u001B[1;32m     21\u001B[0m X_te_n \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(X_te)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Treina\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m W, loss_hist \u001B[38;5;241m=\u001B[39m \u001B[43mreg_mlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_mlp_regression\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_tr_n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_sizes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43meta_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta_f\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlinear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     31\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m fold_losses\u001B[38;5;241m.\u001B[39mappend(loss_hist)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Previsão\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/trabalho_ic_aplicada/models/reg_mlp.py:260\u001B[0m, in \u001B[0;36mtrain_mlp_regression\u001B[0;34m(X_train, y_train, layer_sizes, epochs, eta_i, eta_f, hidden_activation, output_activation, verbose)\u001B[0m\n\u001B[1;32m    256\u001B[0m activations, z_values \u001B[38;5;241m=\u001B[39m forward_pass(x_sample, weights,\n\u001B[1;32m    257\u001B[0m                                    hidden_activation, output_activation)\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[0;32m--> 260\u001B[0m gradients, error \u001B[38;5;241m=\u001B[39m \u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m                               \u001B[49m\u001B[43my_target\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_activation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_activation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# Accumulate squared error\u001B[39;00m\n\u001B[1;32m    264\u001B[0m epoch_squared_error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msum(error\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/trabalho_ic_aplicada/models/reg_mlp.py:174\u001B[0m, in \u001B[0;36mbackward_pass\u001B[0;34m(activations, z_values, weights, target, hidden_activation, output_activation)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mreversed\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(weights))):\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;66;03m# Current layer activation (with bias)\u001B[39;00m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 174\u001B[0m         current_activation \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minsert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Input layer\u001B[39;00m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m         current_activation \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minsert(activations[i], \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# Hidden layer\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/.venv/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:5601\u001B[0m, in \u001B[0;36minsert\u001B[0;34m(arr, obj, values, axis)\u001B[0m\n\u001B[1;32m   5596\u001B[0m values \u001B[38;5;241m=\u001B[39m array(values, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, ndmin\u001B[38;5;241m=\u001B[39marr\u001B[38;5;241m.\u001B[39mndim, dtype\u001B[38;5;241m=\u001B[39marr\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   5597\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indices\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   5598\u001B[0m     \u001B[38;5;66;03m# broadcasting is very different here, since a[:,0,:] = ... behaves\u001B[39;00m\n\u001B[1;32m   5599\u001B[0m     \u001B[38;5;66;03m# very different from a[:,[0],:] = ...! This changes values so that\u001B[39;00m\n\u001B[1;32m   5600\u001B[0m     \u001B[38;5;66;03m# it works likes the second case. (here a[:,0:1,:])\u001B[39;00m\n\u001B[0;32m-> 5601\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmoveaxis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5602\u001B[0m numnew \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mshape[axis]\n\u001B[1;32m   5603\u001B[0m newshape[axis] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m numnew\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/.venv/lib/python3.10/site-packages/numpy/_core/numeric.py:1509\u001B[0m, in \u001B[0;36mmoveaxis\u001B[0;34m(a, source, destination)\u001B[0m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(source) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(destination):\n\u001B[1;32m   1506\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`source` and `destination` arguments must have \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1507\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe same number of elements\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1509\u001B[0m order \u001B[38;5;241m=\u001B[39m [n \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(a\u001B[38;5;241m.\u001B[39mndim) \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m source]\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dest, src \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mzip\u001B[39m(destination, source)):\n\u001B[1;32m   1512\u001B[0m     order\u001B[38;5;241m.\u001B[39minsert(dest, src)\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/.venv/lib/python3.10/site-packages/numpy/_core/numeric.py:1509\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(source) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(destination):\n\u001B[1;32m   1506\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`source` and `destination` arguments must have \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1507\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe same number of elements\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1509\u001B[0m order \u001B[38;5;241m=\u001B[39m [n \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(a\u001B[38;5;241m.\u001B[39mndim) \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m source]\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dest, src \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mzip\u001B[39m(destination, source)):\n\u001B[1;32m   1512\u001B[0m     order\u001B[38;5;241m.\u001B[39minsert(dest, src)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act=leaky_relu HU=32 Ep=100 LR=0.005 → R²=0.6441\n",
      "Act=sigmoid HU=32 Ep=100 LR=0.005 → R²=0.6308\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m learning_rates\u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1e-3\u001B[39m, \u001B[38;5;241m5e-3\u001B[39m, \u001B[38;5;241m1e-2\u001B[39m]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# 1) Random search\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m best_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mhidden_units\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mepochs_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# você pode ajustar n_iter\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# best_cfg = grid_search(X, y, k_fold,\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#                        hidden_units, activations,\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#                        epochs_list, learning_rates)\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# 2) Treino final com CV para coletar tudo\u001B[39;00m\n\u001B[1;32m     18\u001B[0m ls   \u001B[38;5;241m=\u001B[39m best_cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer_sizes\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "Cell \u001B[0;32mIn[18], line 78\u001B[0m, in \u001B[0;36mrandom_search\u001B[0;34m(X, y, k_fold, hidden_units, activations, epochs_list, lrs, n_iter, seed)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m act, hu, ep, lr \u001B[38;5;129;01min\u001B[39;00m sampled_combinations:\n\u001B[1;32m     77\u001B[0m     ls \u001B[38;5;241m=\u001B[39m [X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], hu, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 78\u001B[0m     mean_r2, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_mlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_fold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mact\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAct=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mact\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<7\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m HU=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhu\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m2d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Ep=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mep\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m3d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m LR=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3g\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m → R²=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmean_r2\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mean_r2 \u001B[38;5;241m>\u001B[39m best[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "Cell \u001B[0;32mIn[18], line 23\u001B[0m, in \u001B[0;36mcross_val_mlp\u001B[0;34m(X, y, k_fold, layer_sizes, activation, epochs, lr)\u001B[0m\n\u001B[1;32m     21\u001B[0m X_te_n \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mtransform(X_te)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Treina\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m W, loss_hist \u001B[38;5;241m=\u001B[39m \u001B[43mreg_mlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_mlp_regression\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_tr_n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_sizes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43meta_i\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta_f\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_activation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlinear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     31\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m fold_losses\u001B[38;5;241m.\u001B[39mappend(loss_hist)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Previsão\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/trabalho_ic_aplicada/models/reg_mlp.py:260\u001B[0m, in \u001B[0;36mtrain_mlp_regression\u001B[0;34m(X_train, y_train, layer_sizes, epochs, eta_i, eta_f, hidden_activation, output_activation, verbose)\u001B[0m\n\u001B[1;32m    256\u001B[0m activations, z_values \u001B[38;5;241m=\u001B[39m forward_pass(x_sample, weights,\n\u001B[1;32m    257\u001B[0m                                    hidden_activation, output_activation)\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n\u001B[0;32m--> 260\u001B[0m gradients, error \u001B[38;5;241m=\u001B[39m \u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m                               \u001B[49m\u001B[43my_target\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_activation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_activation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# Accumulate squared error\u001B[39;00m\n\u001B[1;32m    264\u001B[0m epoch_squared_error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msum(error\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Github/Trabalhos_IC_Aplicada/trabalho_ic_aplicada/models/reg_mlp.py:190\u001B[0m, in \u001B[0;36mbackward_pass\u001B[0;34m(activations, z_values, weights, target, hidden_activation, output_activation)\u001B[0m\n\u001B[1;32m    187\u001B[0m error_prev \u001B[38;5;241m=\u001B[39m W_no_bias\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m delta\n\u001B[1;32m    189\u001B[0m \u001B[38;5;66;03m# Apply derivative of hidden activation\u001B[39;00m\n\u001B[0;32m--> 190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hidden_activation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    191\u001B[0m     delta \u001B[38;5;241m=\u001B[39m error_prev \u001B[38;5;241m*\u001B[39m hidden_deriv(activations[i])\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hidden_activation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19,
   "source": [
    "\n",
    "# 2) Treino final com CV para coletar tudo\n",
    "ls   = best_cfg['layer_sizes']\n",
    "act  = best_cfg['activation']\n",
    "ep   = best_cfg['epochs']\n",
    "lr   = best_cfg['lr']\n",
    "\n",
    "all_train_losses = []\n",
    "y_tr_all, y_trp_all = [], []\n",
    "y_te_all, y_tep_all   = [], []\n",
    "cor_tr, cor_te = [], []\n",
    "\n",
    "for train_idx, test_idx in k_fold:\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx].reshape(-1,1), y[test_idx].reshape(-1,1)\n",
    "    scaler = QuantileTransformer(n_quantiles=min(X_tr.shape[0],1000), output_distribution='uniform')\n",
    "    X_tr_n = scaler.fit_transform(X_tr)\n",
    "    X_te_n = scaler.transform(X_te)\n",
    "\n",
    "    W, loss_hist = reg_mlp.train_mlp_regression(\n",
    "        X_tr_n, y_tr, layer_sizes=ls,\n",
    "        epochs=ep, eta_i=lr, eta_f=lr,\n",
    "        hidden_activation=act, output_activation='linear',\n",
    "        verbose=False\n",
    "    )\n",
    "    all_train_losses.append(loss_hist)\n",
    "\n",
    "    y_trp = reg_mlp.predict_mlp_regression(X_tr_n, W, act, 'linear').reshape(-1,1)\n",
    "    y_tep = reg_mlp.predict_mlp_regression(X_te_n, W, act, 'linear').reshape(-1,1)\n",
    "\n",
    "    cor_tr.append(np.corrcoef(y_tr.flatten(), y_trp.flatten())[0,1])\n",
    "    cor_te.append(np.corrcoef(y_te.flatten(), y_tep.flatten())[0,1])\n",
    "\n",
    "    y_tr_all .extend(y_tr.flatten())\n",
    "    y_trp_all.extend(y_trp.flatten())\n",
    "    y_te_all .extend(y_te.flatten())\n",
    "    y_tep_all.extend(y_tep.flatten())\n",
    "\n",
    "# 3) Métricas finais\n",
    "eqms, reqms, r2s, h20, h10, _ = aux.calcular_metricas(\n",
    "    np.array(y_te_all), np.array(y_tep_all), aux)\n",
    "aux.imprimir_metricas(eqms, reqms, r2s, h20, h10)\n",
    "aux.imprimir_correlacoes(cor_tr, cor_te, r2s)\n",
    "aux.analisar_residuos(\n",
    "    np.array(y_tr_all), np.array(y_trp_all),\n",
    "    np.array(y_te_all), np.array(y_tep_all),\n",
    "    aux, titulo=\"MLP Final\"\n",
    ")\n",
    "\n",
    "# 4) Plots de loss\n",
    "aux.plot_folds_loss(all_train_losses)\n"
   ],
   "id": "5bff4b80b61e66c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
