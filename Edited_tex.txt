\documentclass[a4paper,12pt]{article}

% Pacotes essenciais
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{siunitx}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

\title{Reconhecimento de Faces: um Estudo Integrado de Classificadores,\newline Pré‑processamento e Controle de Acesso}
\author{Lucas José Lemos Braz}
\date{Agosto, 2025}

\begin{document}

\maketitle

\section{Introdução}

O texto está organizado da seguinte forma: Seção~\ref{sec:metodo} apresenta o conjunto de dados, as técnicas de pré‑processamento e os classificadores avaliados, descrevendo o protocolo experimental que sustenta a análise. A Seção~\ref{sec:resultados} discute os resultados obtidos em cada atividade
prevista no manual: classificação no espaço de pixels (Atividades~1--2),
descorrelação com PCA (Atividades~3--4), redução de dimensionalidade (Atividades
5--6), aplicação da transformação Box–Cox (Atividade~7) e controle de acesso
(Atividade~8). Finalmente, a Seção~\ref{sec:conclusao} sintetiza as conclusões
principais, identificando as decisões metodológicas que se mostram importantes
para equilibrar desempenho, generalização e eficiência.

\section{Metodologia}
\label{sec:metodo}

\subsection{Conjunto de Dados e Pré‑processamento Inicial}

O estudo utiliza o conjunto Yale~A, composto por quinze indivíduos
fotografados em onze condições de iluminação e pose, totalizando 165 imagens.
Para as primeiras etapas, as imagens foram redimensionadas para
\(30\times 30\)~pixels, produzindo vetores de \(d=900\) atributos após a
\emph{flatten}. Esse tamanho intermediário foi escolhido após um estudo de
escalas (\(20\times 20\), \(30\times 30\) e \(40\times 40\)) que mensurou o
tempo de treinamento e a acurácia dos classificadores. A figura
\ref{fig:tempo_escala} demonstra que a escala de \(30\times 30\) equilibra a
preservação de detalhes faciais e o custo computacional ao evitar a perda de
textura de resoluções menores e o crescimento de tempo de redes profundas em
resoluções maiores.

Para evitar vazamento de dados, todas as normalizações e transformações foram
ajustadas exclusivamente sobre o conjunto de treino de cada repetição. Foram
testadas três normalizações: \texttt{minmax} (escala \([0,1]\)),
\texttt{minmax\_pm1} (\([-1,1]\)) e \texttt{zscore} (média zero e desvio
padrão unitário), aplicadas após a divisão treino/teste. A PCA foi
implementada via decomposição SVD em sua forma compacta: primeiro os dados
foram centrados; depois, quando utilizada como rotação, todos os \(d\)
componentes principais foram mantidos (\(q=d\)); quando utilizada para
redução, apenas os \(q\) maiores autovalores foram retidos. A transformação
Box–Cox, investigada na Atividade~7, foi aplicada componente a componente
apenas após a redução de dimensionalidade; por exigir entradas positivas, um
deslocamento baseado no valor mínimo de cada componente no treino foi somado
antes de estimar o parâmetro \(\lambda\) que maximiza a verossimilhança.

\subsection{Classificadores Avaliados}

Quatro classificadores básicos foram avaliados ao longo das Atividades~1--7:
\emph{Mínimos Quadrados} (MQ), um classificador linear de solução analítica;
\emph{Perceptron Logístico} (PL), ou regressão \emph{softmax}, treinado com
gradiente descendente; e redes neurais \emph{multilayer perceptron} de uma e
duas camadas ocultas (MLP‑1H e MLP‑2H). Para cada modelo (exceto o MQ) foi
realizada uma busca aleatória de 200 configurações dehiperparâmetros, variando
a normalização, a taxa de aprendizado, o otimizador (SGD, Momentum,
Nesterov, RMSProp, Adam), as funções de ativação (\emph{tanh}, sigmoide,
ReLU, Leaky ReLU, ReLU6 e Swish), o número de neurônios por camada e o
clipping de gradiente. O MQ possui um únicohiperparâmetro de regularização
\(L_2\). Cada candidata foi avaliada por dez repetições de validação interna
para reduzir a variância na seleção. Uma vez escolhida a configuração ótima,
o modelo foi re‑ajustado em treino+validação e avaliado em 50 repetições
independentes com divisão estratificada (80\% treino, 20\% teste). Essa
estratificação garante que a proporção de imagens por sujeito seja preservada,
diminuindo o risco de sobreajuste à distribuição de um indivíduo específico.

Na Atividade~8 foram adicionados classificadores destinados à detecção de
anomalias: autoencoders com uma e duas camadas ocultas (AE‑1H e AE‑2H),
One‑Class SVM e Isolation Forest. Esses modelos foram configurados para
aprender a distribuição das faces autorizadas e identificar como intrusos as
amostras que não se ajustarem ao padrão de normalidade.

\subsection{Pipeline Analítico}

\paragraph{Atividades 1–2: Classificação no espaço de pixels} As imagens
redimensionadas foram vetorizadas e submetidas à normalização selecionada
dentro da busca. Os classificadores foram treinados diretamente sobre os 900
atributos, investigando como a resolução e a escala dos dados influenciavam
tempo e acurácia. O objectivo era estabelecer uma linha de base de desempenho
sem pré‑processamento linear.

\paragraph{Atividades 3–4: PCA como rotação} Aqui aplicou‑se PCA com
\(q=d\), ou seja, apenas uma rotação ortogonal da base. A motivação teórica é
descorreralar os atributos, melhorando o condicionamento numérico para
otimizadores de primeira ordem. Foram mantidos todos os componentes, de modo
que nenhuma informação fosse perdida, e o impacto esperado era a aceleração do
treino, sem necessariamente alterar a separabilidade das classes.

\paragraph{Atividades 5–6: PCA com redução de dimensionalidade} A quinta
atividade buscou determinar a dimensionalidade intrínseca do conjunto. Ao
ajustar um PCA no treino completo e somar a variância explicada cumulativa,
verificou‑se que 98\% da variância é retida com apenas \(q=79\) componentes,
mostrando forte redundância nas imagens de faces. Na sexta atividade, o
pipeline foi reexecutado com projeção para esse subespaço de 79 dimensões e
normalização posterior. Cada repetição ajustou o PCA somente nos dados de
treino para evitar vazamento; os 79 vetores próprios (\emph{eigenfaces}) foram
então usados para projetar treino e teste.

\paragraph{Atividade 7: PCA seguido de Box–Cox e Z‑Score} Nesta etapa,
testou‑se ahipótese de que aproximar a distribuição de cada componente
principal a uma Gaussiana poderia beneficiar classificadores lineares. Após a
projeção para \(q=79\), aplicou‑se a transformação Box–Cox a cada dimensão,
estimando \(\lambda\) apenas sobre os dados de treino e garantindo
positividade. Em seguida, realizou‑se uma normalização Z‑Score. O custo
computacional adicional foi contabilizado.



Por fim, investigou-se o uso dos classificadores para distinguir usuários autorizados de um intruso. Duas formulações foram comparadas: 
\begin{enumerate}
    \item tratar o intruso como uma 16ª classe e treinar classificadores binários ou multiclasse no pipeline \texttt{PCA ($q=79$)\,$\rightarrow$\,Box--Cox\, $\rightarrow$\,Z-Score\,$\rightarrow$\,classificador},

    \item treinar modelos unários de detecção de anomalias apenas com dados de usuários legítimos, definindo limiares a partir dos percentis dos escores de reconstrução ou de anomalia. 
\end{enumerate}

No cenário binário, a métrica central é a sensibilidade para detectar o intruso conhecido;  já na abordagem unária, prioriza-se uma baixa taxa de falsos negativos (intrusos aceitos) em relação aos falsos positivos (usuários legítimos rejeitados). A inclusão de 11 imagens próprias no conjunto de testes permitiu simular a presença do intruso nessas análises.


\section{Resultados e Discussão}
\label{sec:resultados}

\subsection*{Atividades 1–2: Classificação no Espaço de Pixels}

A Tabela~\ref{tab:a1a2_res} apresenta as estatísticas de acurácia e tempo de execução obtidas pelos quatro classificadores quando treinados diretamente nos
vetores de 900 pixels (escala \(30\times 30\)). Todos os valores são médias
sobre 50 repetições com desvio padrão. Observa‑se que o classificador de
Mínimos Quadrados (MQ) apresentou a melhor acurácia média e o menor desvio
padrão, contrariando a intuição de que redes neurais profundas sempre
superariam modelos lineares. As MLPs, embora capazes de aprender fronteiras
não lineares, sofreram maior variabilidade e não ultrapassaram o desempenho
lineares, fenômeno compatível com o regime de poucas amostras por classe do
conjunto Yale~A. Além disso, o tempo de treino cresce drasticamente à medida
que se adicionam camadas e neurônios.

\begin{table}[h]
\centering
\caption{Atividades~1–2 — Desempenho sem PCA (\(d=900\)). Os valores são
médias de 50 repetições.}
\label{tab:a1a2_res}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Classificador} & \textbf{Média} & \textbf{Min} & \textbf{Max} & \textbf{Med} & \textbf{DP} & \textbf{Tempo Total (ms)}\\\midrule
MQ & 0.965 & 0.911 & 1.000 & 0.978 & 0.024 & 8.516 \\
PL & 0.922 & 0.844 & 1.000 & 0.933 & 0.033 & 38.442 \\
MLP-1H & 0.928 & 0.844 & 0.978 & 0.933 & 0.039 & 252.304 \\
MLP-2H & 0.930 & 0.800 & 1.000 & 0.933 & 0.039 & 942.703 \\
\bottomrule
\end{tabular}%
}
\end{table}

A Figura~\ref{fig:tempo_escala} complementa esses resultados, mostrando o
crescimento do tempo de processamento em função da resolução. A escala
\(30\times 30\) foi selecionada por equilibrar fidelidade visual e custo,
permitindo que as atividades subsequentes fossem conduzidas com repetição
estatística robusta.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\textwidth]{tempo_escala_A1_A2.png}
  \caption{Tempo médio de processamento em função da resolução das imagens
  nas Atividades~1–2. O custo das MLPs cresce superlinearmente com a
  dimensionalidade, justificando a escolha da resolução intermediária.}
  \label{fig:tempo_escala}
\end{figure}

\subsection*{Atividades 3–4: PCA como Rotação (\(q=d\))}

Ao aplicar o PCA com \(q=d\), os dados são rotacionados para um sistema de
coordenadas ortogonais sem perda de informação. A Tabela~\ref{tab:pca_rot_res}
mostra que essa descorrelação reduziu drasticamente o tempo de treinamento de
todos os classificadores baseados em gradiente (PL e MLPs). Entretanto,
observou‑se uma queda de acurácia, especialmente nos modelos não lineares. O
MQ, cuja solução é analítica, manteve praticamente o desempenho, sugerindo
que a rotação não alterou a separabilidade linear das classes. Para as MLPs,
ahipótese de que a descorrelação facilitaria a otimização não se traduziu em
ganhos de acurácia; ao contrário, a projeção desalinhou direções naturais de
separação, tornando mais difícil a aprendizagem de fronteiras não lineares.

\begin{table}[h]
\centering
\caption{Atividades~3–4 — Desempenho com PCA como rotação
\((q=d=900)\).}
\label{tab:pca_rot_res}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Classificador} & \textbf{Média}& \textbf{Min} & \textbf{Max} & \textbf{Med} & \textbf{DP} & \textbf{Tempo Total (ms)} \\
\midrule
MQ & 0.961 & 0.889 & 1.000 & 0.978 & 0.028 & 2.258 \\
PL & 0.867 & 0.778 & 0.933 & 0.867 & 0.037 & 29.576 \\
MLP-1H & 0.826 & 0.644 & 0.956 & 0.822 & 0.062 & 109.268 \\
MLP-2H & 0.840 & 0.689 & 0.956 & 0.822 & 0.053 & 299.309 \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection*{Atividades 5–6: Redução de Dimensionalidade com PCA (\(q=79\))}

O estudo da variância explicada cumulativa indicou que cerca de 98\% da
informação das imagens está contida nos 79 primeiros componentes principais
(Figura~\ref{fig:var_explicada}). Esse resultado confirma a forte redundância
intrínseca em imagens de faces controladas e motiva a compressão para
\(q=79\). Visualmente, as chamadas \emph{eigenfaces} iniciais capturam
gradações de iluminação e, somente após as primeiras direções, traços faciais
mais finos se tornam visíveis (Figura~\ref{fig:eigenfaces}). A Tabela
\ref{tab:pca_red_res} revela que a projeção para 79 dimensões reduziu o
custo de treino em ordens de grandeza e, simultaneamente, recuperou ou mesmo
melhorou a acurácia dos classificadores em relação ao espaço original. O PL e
a MLP‑1H igualaram a performance do MQ, sugerindo que os 2\% de variância
descartados continham principalmente ruído. Embora a MLP‑2H continue mais
lenta, seus resultados são comparáveis ao MQ, indicando que arquiteturas
profundas não são necessárias quando o espaço é adequadamente compactado.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{pca_variance_explained_A3.png}
  \caption{Variância explicada acumulada em função do número de componentes
  principais. A linha tracejada destaca \(q=79\), ponto a partir do qual mais de
  98\% da variância total é preservada.}
  \label{fig:var_explicada}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{eigenfaces_visualization.png}
  \caption{As dez primeiras \emph{eigenfaces} obtidas pelo PCA. As primeiras
  componentes correspondem a variações globais de iluminação; componentes
  posteriores capturam contornos faciais comuns.}
  \label{fig:eigenfaces}
\end{figure}

\begin{table}[h]
\centering
\caption{Atividades~6 — Desempenho com PCA reduzida
\((q=79)\).}
\label{tab:pca_red_res}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Classificador} & \textbf{Média}& \textbf{Min} & \textbf{Max} & \textbf{Med} & \textbf{DP} & \textbf{Tempo Total (ms)} \\
\midrule
MQ & 0.959 & 0.889 & 1.000 & 0.956 & 0.029 & 0.260 \\
PL & 0.959 & 0.889 & 1.000 & 0.956 & 0.029 & 21.692 \\
MLP-1H & 0.956 & 0.889 & 1.000 & 0.956 & 0.027 & 53.646 \\
MLP-2H & 0.948 & 0.844 & 1.000 & 0.956 & 0.034 & 442.021 \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection*{Atividade 7: PCA com Box–Cox}

A aplicação da transformação Box–Cox após a redução de dimensionalidade
pretendia "gaussianizar" os 79 componentes principais, partindo da
hipótese de que classificadores lineares beneficiariam‑se de entradas mais
próximas de uma distribuição normal. Contudo, o Teorema do Limite Central
indica que cada componente principal já é uma combinação de centenas de
pixels, e portanto tende naturalmente à gaussianidade. A Figura
\ref{fig:comparativo_a7} confirma empiricamente que a transformação Box–Cox
não apenas não contribuiu para aumentar a acurácia, como produziu uma
degradação sistemática em todos os classificadores testados. O custo de
ajustar \(\lambda\) para cada componente em cada repetição não se traduziu em
melhorias, reforçando que técnicas de pré‑processamento devem ser aplicadas
com base em análises específicas dos dados e não como receitas universais.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{comparativo_A7_acc.png}
  \caption{Comparação de acurácia média entre a redução de dimensionalidade
  com PCA (Atividade~6) e a aplicação adicional de Box–Cox (Atividade~7). A
  degradação é consistente em todos os modelos, indicando que a
  transformação não linear distorceu a geometria favorável do subespaço PCA.}
  \label{fig:comparativo_a7}
\end{figure}

\subsection*{Atividade 8: Controle de Acesso}

O desafio final foi construir um mecanismo de controle de acesso capaz de
reconhecer usuários autorizados e rejeitar intrusos. Duas filosofias foram
comparadas. Na \emph{abordagem supervisionada} (binária), o intruso é
considerado uma 16ª classe vista durante o treino; na \emph{abordagem não
supervisionada} (unária), o sistema aprende somente a "normalidade" das
faces autorizadas e rejeita o que se afasta desse padrão. Para ambas, o
pipeline de pré‑processamento consistiu em PCA com \(q=79\), transformação
Box–Cox e normalização Z‑Score.

A Tabela~\ref{tab:a8_binario_res} resume as
médias e desvios padrão de acurácia, taxa de falsos negativos (FNR), taxa de
falsos positivos (FPR), sensibilidade (\emph{recall}) e precisão para quatro
classificadores. A métrica crítica em segurança é a FNR (probabilidade de
aceitar um intruso). Os resultados mostram FNR praticamente nula e
sensibilidade unitária para MQ e MLP‑1H, dando a falsa impressão de um
sistema perfeito. Entretanto, essa performance decorre do fato de o modelo
treinar explicitamente com o intruso conhecido: ele apenas memoriza as
características daquela pessoa específica. Em ambientes reais, onde
intrusos diferentes podem aparecer, esse sistema não generaliza e
torna‑se inseguro. A precisão modesta (por volta de 0.38) e a FPR acima de
10\% indicam que muitos usuários legítimos seriam barrados se o limiar de
decisão fosse ajustado para alcançar FNR zero.

\begin{table}[h]
\centering
\caption{Atividade 8 — Métricas de controle de acesso na abordagem binária
(supervisionada). Valores médios \(\pm\) desvio padrão.}
\label{tab:a8_binario_res}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccc}
\toprule
\textbf{Classificador} & \textbf{Acurácia} & \textbf{FNR} & \textbf{FPR} & \textbf{Sensibilidade} & \textbf{Precisão} \\
\midrule
MQ & 0.886\,\pm\,0.052 & 0.000\,\pm\,0.000 & 0.122\,\pm\,0.055 & 1.000\,\pm\,0.000 & 0.387\,\pm\,0.119 \\
PL & 0.877\,\pm\,0.055 & 0.107\,\pm\,0.205 & 0.124\,\pm\,0.056 & 0.893\,\pm\,0.205 & 0.355\,\pm\,0.135 \\
MLP-1H & 0.886\,\pm\,0.052 & 0.000\,\pm\,0.000 & 0.122\,\pm\,0.055 & 1.000\,\pm\,0.000 & 0.387\,\pm\,0.119 \\
MLP-2H & 0.884\,\pm\,0.054 & 0.033\,\pm\,0.137 & 0.122\,\pm\,0.055 & 0.967\,\pm\,0.137 & 0.379\,\pm\,0.130 \\
\bottomrule
\end{tabular}%
}
\end{table}

\paragraph{Detecção de anomalias (abordagem unária)} Na abordagem unária,
somente as imagens dos usuários autorizados foram usadas para treinar um
modelo de normalidade. O limiar de decisão foi definido por percentis dos
scores de anomalia no conjunto de treino, sem qualquer informação sobre o
intruso. A Tabela~\ref{tab:a8_unaria_res} mostra que, como esperado, a FNR
é maior do que na abordagem binária, pois o intruso nunca é visto durante o
treino. Ainda assim, métodos como o autoencoder de uma camada (AE‑1H) e o
Isolation Forest alcançaram precisão superior a 0.80 com FPRs inferiores a
6\%, demonstrando boa capacidade de rejeitar intrusos não vistos. Os baixos
FNRs do One‑Class SVM e do AE‑2H acontecem às custas de uma FPR
excessivamente alta: esses modelos rotularam praticamente todos os usuários
como intrusos, ilustrando o perigo do sobreajuste em espaços de alta
dimensionalidade mesmo após a redução com PCA.

\begin{table}[h]
\centering
\caption{Atividade 8 — Métricas de controle de acesso na abordagem unária
(detecção de anomalias). Valores médios \(\pm\) desvio padrão.}
\label{tab:a8_unaria_res}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccc}
\toprule
\textbf{Classificador} & \textbf{Acurácia} & \textbf{FNR} & \textbf{FPR} & \textbf{Sensibilidade} & \textbf{Precisão} \\
\midrule
PCA\_Baseline & 0.748\,\pm\,0.044 & 0.753\,\pm\,0.136 & 0.031\,\pm\,0.041 & 0.247\,\pm\,0.136 & 0.773\,\pm\,0.274 \\
AE\_1H & 0.799\,\pm\,0.051 & 0.529\,\pm\,0.143 & 0.057\,\pm\,0.046 & 0.471\,\pm\,0.143 & 0.801\,\pm\,0.152 \\
AE\_2H & 0.367\,\pm\,0.037 & 0.000\,\pm\,0.000 & 0.912\,\pm\,0.053 & 1.000\,\pm\,0.000 & 0.326\,\pm\,0.013 \\
OneClassSVM & 0.369\,\pm\,0.035 & 0.000\,\pm\,0.000 & 0.908\,\pm\,0.050 & 1.000\,\pm\,0.000 & 0.327\,\pm\,0.012 \\
IsolationForest & 0.780\,\pm\,0.047 & 0.613\,\pm\,0.130 & 0.047\,\pm\,0.050 & 0.387\,\pm\,0.130 & 0.819\,\pm\,0.171 \\
\bottomrule
\end{tabular}%
}
\end{table}

\paragraph{Comparação conceitual} A Tabela~\ref{tab:a8_comp}
sintetiza as diferenças filosóficas entre as duas abordagens. A
supervisionada visa maximizar o F1‑Score do intruso visto, mas falha
completamente diante de novos intrusos. A detecção de anomalias, embora
apresente FNR mais elevado, corresponde à prática recomendada em sistemas de
segurança: modelar apenas o comportamento normal e usar limiares de
rejeição calibrados, eventualmente combinando múltiplos detectores e
resortindo a verificações adicionais (como autenticação de dois fatores) nos
casos fronteiriços.

\begin{table}[h]
\centering
\caption{Contraste entre as abordagens supervisionada (binária) e não
supervisionada (unária) para controle de acesso.}
\label{tab:a8_comp}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lll}
\toprule
\textbf{Característica} & \textbf{Abordagem Binária} & \textbf{Abordagem Unária} \\
\midrule
Hipótese & O intruso é uma classe conhecida. & O intruso é uma anomalia desconhecida. \\
Dados de treino & Autorizados + intruso específico & Apenas autorizados \\
Tarefa & Separar classes (discriminativa) & Modelar a normalidade (generativa/fronteira) \\
Generalização & Baixa: falha com intrusos não vistos. & Alta: potencial para detectar qualquer intruso. \\
Validade no mundo real & Fraca: sistema quebradiço e inseguro. & Forte: abordagem padrão em segurança. \\
\bottomrule
\end{tabular}%
}
\end{table}

\paragraph{Imagens do intruso} Para documentação, o relatório reserva
espaço para a inserção manual de nove das onze imagens utilizadas como
intruso, distribuídas nas Figuras~\ref{fig:intruso1}–\ref{fig:intruso9}. Cada
figura deve mostrar uma fotografia distinta do intruso. Mantiveram‑se duas
imagens fora do relatório para economia de espaço e por serem redundantes.

\begin{figure}[h]
  \centering
  \rule{3cm}{3cm}
  \caption{Imagem do intruso (espaço reservado).}
  \label{fig:intruso1}
\end{figure}


\section{Conclusão}
\label{sec:conclusao}

Ao longo deste estudo foi construída uma narrativa experimental que justificou
cada decisão metodológica. Iniciou‑se com a análise de escalas e a
constatação de que a resolução \(30\times 30\) é suficiente para preservar
informação facial relevante sem inviabilizar o treinamento repetido de
classificadores. O classificador de Mínimos Quadrados estabeleceu um
referencial forte, superando redes neurais em acurácia e estabilidade quando
os dados são utilizados diretamente no espaço de pixels. A descorrelação via
PCA (Atividades~3–4) acelerou os treinos, mas evidenciou que a rotação não
altera o poder discriminativo intrínseco do problema.

O passo decisivo foi a redução de dimensionalidade (Atividades~5–6):
comprimir 900 atributos em 79 preservou mais de 98\% da variância e
recuperou ou melhorou a acurácia, mostrando que a maior parte da estrutura
discriminativa das faces reside em um subespaço de baixa dimensão. Tal
compressão reduziu o risco de sobreajuste das MLPs e permitiu que modelos
lineares e redes rasas tivessem desempenho semelhante. Em contraste, a
transformação Box–Cox testada na Atividade~7 ilustrou o risco de aplicar
"boas práticas" sem análise prévia: embora concebida para aproximar
distribuições de Gauss, ela distorceu um espaço já bem comportado e degradou
os resultados.

No cenário aplicado de controle de acesso (Atividade~8), a comparação entre
as abordagens supervisionada e unária traz uma lição central. Treinar com um
intruso específico leva a taxas de falsos negativos nulas para aquele
indivíduo, mas não oferece proteção contra intrusos desconhecidos. A
detecção de anomalias, embora apresente FNR maior, proporciona a única
estratégia capaz de generalizar para intrusos arbitrários. Em implantação,
recomenda‑se calibrar limiares com base na tolerância ao risco, adotar
verificações complementares (como autenticação de dois fatores) para casos
próximos ao limiar e combinar detectores (autoencoder + Isolation Forest)
quando necessário.

Em síntese, o relatório demonstra que pré‑processamento e escolha
metodológica são mais determinantes para o sucesso de um sistema de
reconhecimento de faces do que a complexidade do classificador em si. A
história construída nestas páginas ilustra como cada decisão, ancorada em
evidências quantitativas e justificativas teóricas, contribui para um
equilíbrio entre desempenho, robustez e eficiência computacional.

\end{document}
